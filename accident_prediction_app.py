# -*- coding: utf-8 -*-
"""Accident_Prediction_App.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/mariammoh55/accident-prediction-app-ipynb.bf55646a-07bb-4907-a87f-861d21cc32dd.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20251205/auto/storage/goog4_request%26X-Goog-Date%3D20251205T002231Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D158fcf929ba1ce2ad4b67f24bd7e1166fdad851fd227ba102c61c0bb12c802fa51c84f22d7cdd6b986461f04cbb688c973a07f4106721a6d00ceb7c0d53b4b69566f8ead28780fd4d15a0a83a3d48f3a52c1256fc162d032f6fd0b5a6fdf2834fbec619258de178788d644c9f312c45c9d96a11b2f68af43a81ad0ac908e3cea5c9733d425e58c0e626aa14c8eb3af3418ac67c12241b4d5bf069dc92b8d2b29e768e78f761a40a2790c9769a2ea2d137ad585db6afc7672cbb8c0e1fdda969cdd3c70b7a2721dbc458cf2b9d8c96cff234c8d96cfdd27dc627476289dee97740e5767678f38ad27d5d3232d64bc5c6275fd56e54eb832efeae7545d86fc3d29
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
mariammoh55_accident_models_path = kagglehub.dataset_download('mariammoh55/accident-models')
mariammoh55_project_cleaned_path = kagglehub.notebook_output_download('mariammoh55/project-cleaned')

print('Data source import complete.')

import warnings
warnings.filterwarnings('ignore')
!pip install streamlit
import streamlit as st
import pandas as pd
import numpy as np
import joblib

model = joblib.load("/kaggle/input/accident-models/lgb_model.pkl")
thresholds = joblib.load("/kaggle/input/accident-models/thresholds (2).pkl")
le = joblib.load("/kaggle/input/accident-models/label_encoder.pkl")
freq_maps = joblib.load("/kaggle/input/accident-models/freq_maps.pkl")
scaler = joblib.load("/kaggle/input/accident-models/scaler (1).pkl")

# Streamlit title
st.title("Accident Severity Prediction")

# Example inputs
speed_limit = st.number_input("Speed Limit", min_value=0, max_value=100, value=30)
urban_rural = st.selectbox("Urban or Rural Area", [1, 2, 3])
light_condition = st.selectbox("Light Conditions", [
    'Daylight: Street light present',
    'Darkness: Street lights present and lit',
    'Darkness: Street lighting unknown',
    'Darkness: Street lights present but unlit',
    'Darkeness: No street lighting'
])
road_surface = st.selectbox("Road Surface Conditions", ['Dry','Wet/Damp','Frost/Ice','Snow','Flood (Over 3cm of water)'])

# Prepare input
input_df = pd.DataFrame({
    "Speed_limit": [speed_limit],
    "Urban_or_Rural_Area": [urban_rural],
    "Light_Conditions": [light_condition],
    "Road_Surface_Conditions": [road_surface],
})

# Mapping categorical features
light_mapping = {
    'Daylight: Street light present': 4,
    'Darkness: Street lights present and lit': 3,
    'Darkness: Street lighting unknown': 2,
    'Darkness: Street lights present but unlit': 1,
    'Darkeness: No street lighting': 0,
}
surface_mapping = {
    'Dry': 4, 'Wet/Damp': 3, 'Frost/Ice': 2, 'Snow': 1, 'Flood (Over 3cm of water)': 0,
}

input_df['Light_Conditions'] = input_df['Light_Conditions'].map(light_mapping).fillna(-1)
input_df['Road_Surface_Conditions'] = input_df['Road_Surface_Conditions'].map(surface_mapping).fillna(-1)

# Feature engineering
input_df['Speed_Urban_Rural'] = input_df['Urban_or_Rural_Area'] * input_df['Speed_limit']
input_df['Light_Road_Interaction'] = input_df['Light_Conditions'] * input_df['Road_Surface_Conditions']

# Add missing columns with default 0
for col in model.feature_name_:
    if col not in input_df.columns:
        input_df[col] = 0

# Apply frequency mapping only to existing columns
for col in freq_maps:
    if col in input_df.columns:
        input_df[col] = input_df[col].map(freq_maps[col]).fillna(0)

# Prediction
probs = model.predict_proba(input_df)
pred = np.zeros(len(probs), dtype=int)
for i, th in enumerate(thresholds):
    mask = probs[:, i] >= th
    pred[mask] = i

# Handle rows where no class met threshold
mask_no_class = ~np.any(probs >= thresholds, axis=1)
pred[mask_no_class] = np.argmax(probs[mask_no_class], axis=1)

pred_labels = le.inverse_transform(pred)

st.write("Predicted Accident Severity:", pred_labels[0])

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# streamlit
# numpy
# pandas
# scikit-learn
# lightgbm
# joblib
#

